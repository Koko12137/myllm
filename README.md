# MyLLM: My Large Language Model in action

è®°å½•ä¸€ä¸‹åŠ¨æ‰‹è¾¹åšè¾¹å­¦Large Language Modelçš„è¿‡ç¨‹ã€‚ä¸è¦å½“ä¸€ä¸ªè°ƒåŒ…ä¾ ï¼Œè¦çŸ¥é“ç»†èŠ‚ï¼Œä»¥åŠä¸ºä»€ä¹ˆè¿™ä¹ˆåšã€‚

## TODO List

### âœ… å·²å®Œæˆ

- [x] [2025.2.11] è®­ç»ƒä¸€ä¸ªåˆ†è¯å™¨
- [x] [2025.2.13] å‚è€ƒminimindå¤ç°å¤§æ¨¡å‹é¢„è®­ç»ƒï¼Œå¹¶å‚è€ƒqwen2å’Œllamaå°†å®ç°è¿ç§»åˆ°HFçš„Transformersè§„èŒƒ

### ğŸ•¥ è¿›è¡Œä¸­

- [ ] [2025.2.15] æ”¹è¿›Attentionæœºåˆ¶ä»¥åŠå¼•å…¥MoE
  - [x] [2025.2.15] SDPAæ”¯æŒ
    - [ ] SDPAæ¨¡å‹è®­ç»ƒä¸­ï¼ŒåŒæ ·batchå³°å€¼æ˜¾å­˜æ¶ˆè€—ä¸è®­ç»ƒæ—¶é—´ä¸‹é™äº†ä¸€åŠï¼Œå¢åŠ batch
  - [ ] FlashAttentionæ”¯æŒ
  - [ ] ç¨€ç–æ³¨æ„åŠ›ä¸çº¿æ€§æ³¨æ„åŠ›
  - [ ] Deepseek V3çš„MLAå’ŒMoE

### ğŸ—“ è®¡åˆ’å†…

- [ ] Generationç›¸å…³ï¼Ÿ
- [ ] ä¿®æ”¹RoPE
- [ ] æ·»åŠ shortcut MoE
- [ ] å¼ºåŒ–å­¦ä¹ ä¸è’¸é¦
- [ ] æ‰‹åŠ¨é…ç½®DeepSpeedåˆ†å¸ƒå¼è®¡ç®—ï¼Œå› ä¸ºç°åœ¨çš„è¿è¡Œæ–¹æ³•åœ¨`io_operation`å­˜åœ¨é—®é¢˜
  - [ ] æ˜¯å¦éœ€è¦è‡ªå®šä¹‰Trainerï¼ˆè‡ªå®šä¹‰DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒï¼‰ï¼Ÿ
- [ ] ...

### æ›´æ–°æ—¥å¿—

- [2025.2.13]
å®ŒæˆTokenizerè®­ç»ƒï¼ŒDebugè·‘é€šåŸºç¡€æ¨¡å‹

- [2025.2.15]
ä¿®å¤PretrainDatasetåœ¨ç”Ÿæˆlabelsæ—¶ä¼šæ¯”input_idså¤šä¸€ä¸ªçš„é—®é¢˜ï¼Œå¢åŠ å¯¹SDPAå®ç°çš„FlashAttentionæ”¯æŒ

## ğŸ§‘â€ğŸ’» QA

1. æ€ä¹ˆè®©tokençš„embeddingåœ¨æŸç§è¯­ä¹‰ç¯å¢ƒä¸‹å‘ˆç°å‡ºç‰¹å®šçš„å¯åŠ æ€§å‘¢ï¼Ÿæ¯”å¦‚ï¼š

    - è¿·ä½ ç‰ˆçš„ç•ªèŒ„æ˜¯åœ£å¥³æœï¼šVector[è¿·ä½ ç‰ˆçš„] + Vector[ç•ªèŒ„] = Vector[åœ£å¥³æœ] â‰  Vector[å¥‡å¼‚æœ]
    - ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸èƒ½ä»…ä»…å°†å‘é‡è¡¨ç¤ºå­¦ä¹ å±€é™äºå…±ç°æ€§çº¦æŸ

2. Debugä¸­å‘ç°ï¼Œç”±`GenerationMixin`ç”Ÿæˆçš„`position_ids`ä¸­ï¼Œ`attention_mask == 0`çš„éƒ¨åˆ†å…¨ä¸º1ï¼Œè¿™ä¸ªç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ

3. [2025.2.15] Padding tokençš„åµŒå…¥åº”è¯¥éšç€æ¨¡å‹çš„æ›´æ–°è€Œæ›´æ–°å—ï¼Ÿ

   [2025.2.16] çœ‹äº†ä¸€ä¸‹Qwen2ForCausalLMçš„embed_tokenså¯¹åº”çš„paddingåµŒå…¥ï¼Œå¹¶ä¸ä¸º0å‘é‡

4. [2025.2.15] ç›´æ¥ä¿®æ”¹eager_attnä¸ºsdpaåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°äº†nanå€¼

   1. [2025.2.16] åŸæ¥å†™çš„`attention_mask(bsz, n, seq_len, seq_len)`ï¼Œåœ¨`padding`çš„è¡Œå…¨ä¸º`mask`ï¼Œè¿™ä¸ªä½¿å¾—åœ¨è®¡ç®—`softmax`å‡ºç°é™¤0ï¼Œå‚ç…§Qwen2çš„å¤„ç†æ–¹å¼ï¼Œå¦‚æœå‰kä¸ª`token`æ˜¯`padding`ï¼Œé‚£ä¹ˆ`attention mask`å¯¹åº”çš„`[k, seq_len]`å…¨ä¸º0ï¼Œè€Œä¸æ˜¯æœ€å°å€¼å¡«å……ï¼Œä»¥è§„é¿ä¸Šè¿°æƒ…å†µã€‚
   2. [2025.2.16] è§£å†³ä¸Šè¿°é—®é¢˜åï¼ŒForward Passingæ²¡æœ‰å†å‡ºç°Nanï¼Œè€ŒBackwardå¼•å‘äº†Nanï¼Œåœ¨æŠŠ`MyLLMRMSNorm`å»æ‰çš„æƒ…å†µä¸‹ä¸ä¼šå‡ºç°Nanï¼Œé—®é¢˜è¿˜åœ¨æ’æŸ¥ã€‚
   3. [2025.2.19] Backwardçš„Nané—®é¢˜å·²è§£å†³ï¼Œåœ¨Debugè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†Qwen2çš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œé€ä¸ªæ¨¡å—æ›¿æ¢ï¼Œæœ€åå°†é—®é¢˜å®šä½åœ¨`nn.Embedding(..., padding_idx=0)`å‚æ•°è®¾ç½®ä¸Šï¼Œè¯¥è®¾ç½®ä½¿å¾—åœ¨`MyLLMForCausalLM`çš„`lm_head`åœ¨åå‘ä¼ æ’­æ—¶`grad_output`ï¼ˆè¯¥å‚æ•°é€šè¿‡backwardé’©å­å‡½æ•°è·å¾—ï¼‰å‡ºç°äº†Nanï¼ŒæŠŠè¿™ä¸ªå‚æ•°å»æ‰å°±å¥½äº†ï¼Œä½†æ˜¯ä½œç”¨æœºç†ä»ä¸æ˜ã€‚æ¨¡å—æ›¿æ¢å®éªŒå‚è€ƒï¼š[modeling_qwen.py](./test/modeling_qwen.py)

## 1. Tokenizer

ä½¿ç”¨BPEç®—æ³•è¿›è¡Œåˆ†è¯ï¼Œå‚ç…§[Minimind](https://github.com/jingyaogong/minimind)åˆ†è¯å™¨çš„è®­ç»ƒ.

**ä½¿ç”¨æ•°æ®**:

1. [Minimind](https://github.com/jingyaogong/minimind)åˆ†è¯å™¨è®­ç»ƒè¯­æ–™

2. [IndustryCorpus 2.0](https://data.baai.ac.cn/details/BAAI-IndustryCorpus-v2)çš„ç¼–ç¨‹ã€äººå·¥æ™ºèƒ½-æœºå™¨å­¦ä¹ éƒ¨åˆ†

**æ•°æ®å¤„ç†**:

- æ ¸å¿ƒæ­¥éª¤ï¼š

    1. ç›´æ¥è®­ç»ƒTokenizer
    2. æ£€æŸ¥Mergesåˆå¹¶è§„åˆ™ï¼Œäººå·¥æå–ä¸åˆç†çš„åˆå¹¶è§„åˆ™
    3. å°†è¿ç»­ç¬¦å·ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œæ›¿æ¢

- å‚è€ƒï¼š [0-tokenizer.ipynb](./notebooks/0-tokenizer.ipynb)

**å…¶ä»–å‚è€ƒèµ„æ–™**ï¼š

[Huggingface NLP Course - 6.ğŸ¤—TOKENIZERSåº“](https://huggingface.co/learn/nlp-course/zh-CN/chapter6/1?fw=pt)

### **1.2 NOTES:**

2025.2.11

1. åœ¨ä¸è¿›è¡ŒåŸå§‹æ•°æ®æ¸…æ´—çš„æƒ…å†µä¸‹è¿›è¡Œåˆ†è¯å™¨è®­ç»ƒä¼šå‡ºç°å¾ˆå¤šçš„è¿`ç©ºæ ¼`æ ¼å’Œ`=`ç­‰ç¬¦å·

2. åˆ†è¯å™¨è§£ç åœ¨ç‰¹æ®Štokenåä¼šè‡ªåŠ¨é™„åŠ ç©ºæ ¼ï¼Œè¿™ä¸ªbugç›®å‰è¿˜æ²¡è§£å†³

## 2. Pre-Train

å‚ç…§[Qwen2](https://github.com/huggingface/transformers/blob/main/src/transformers/models/qwen2/modeling_qwen2.py)å®ç°æ¨¡å‹ä¸»è¦æ¶æ„ï¼Œå‚ç…§[LLAMA](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)å®ç°Eager GQAï¼Œå‚ç…§[Qwen2](https://github.com/huggingface/transformers/blob/main/src/transformers/models/qwen2/modeling_qwen2.py)å®ç°SDPAï¼Œå‚ç…§[ååˆ†é’Ÿè¯»æ‡‚æ—‹è½¬ç¼–ç ï¼ˆRoPEï¼‰](https://zhuanlan.zhihu.com/p/647109286)å®ç°æ—‹è½¬ä½ç½®ç¼–ç ã€‚

**ä½¿ç”¨æ•°æ®:**

**æ•°æ®å¤„ç†:**

- æ ¸å¿ƒæ­¥éª¤ï¼ˆè¯•äº†ä¸€ä¸‹é¢„å¤„ç†é€Ÿåº¦å¤ªæ…¢ï¼Œç›®å‰è®­ç»ƒé€Ÿåº¦ä¹Ÿå¤ªæ…¢äº†ï¼Œæ‰€ä»¥å…ˆåšæ¨¡å‹ç»“æ„å»äº†ï¼‰ï¼š

    1. è®¡ç®—æ–‡æœ¬hashå€¼ï¼Œå¯¹é‡å¤éƒ¨åˆ†è¿›è¡Œå†hash
    2. å¯¹å†hashé‡å¤éƒ¨åˆ†æ£€æŸ¥å…¶æ˜¯å¦ç›¸åŒï¼Œç›¸åŒåˆ™åˆ é™¤
    3. å¯¹è¶…é•¿éƒ¨åˆ†æ–‡æœ¬è¿›è¡Œåˆ†æ®µ

- å‚è€ƒï¼š [1-pretrain.ipynb](notebooks/1-pretrain.ipynb)

### **2.2 NOTES:**

2025.2.15

**â‘ ** åŸºç¡€å®éªŒå·²è·‘é€šï¼Œ6å¡è®­ç»ƒè€—æ—¶çº¦41å°æ—¶ï¼ŒLosså¦‚å›¾ï¼š

  ![alt text](assets/pretrain-loss.png)

**â‘¡** Debug Qwen2æ¨¡å‹æ¨ç†è¿‡ç¨‹ï¼Œå¯¹æ¨¡å‹æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œå¢åŠ å¯¹SDPAçš„æ”¯æŒ

1. å…³æ³¨GenerationMixinåšçš„nä»¶äº‹
   1. ç”Ÿæˆposition_idsç­‰

   2. åˆå§‹åŒ–Cacheå®ä¾‹

      - æ£€æŸ¥æ˜¯å¦æœ‰ä¼ å…¥çš„Cacheå®ä¾‹
      - æ£€æŸ¥æ¨¡å‹æ”¯æŒçš„Cacheç±»å‹
      - æ²¡æœ‰æ”¯æŒç±»å‹æ—¶æ£€æŸ¥æ˜¯å¦æ”¯æŒåŠ¨æ€Cacheç±»å‹

   3. å°†å‡†å¤‡å¥½çš„å‚æ•°ä¼ å…¥ç”Ÿæˆæ–¹æ³•ï¼Œç”±ç”Ÿæˆæ–¹æ³•è°ƒç”¨æ¨¡å‹çš„`forward`æ–¹æ³•

      `GenerationMixin`é›†æˆäº†å¤šç§é‡‡æ ·æ–¹æ³•ï¼Œå¦‚`GreedySearch`ï¼Œ`BeamSearch`ä»¥åŠ`Sample`ç­‰ï¼›

2. Flash Attention

   - å‚è€ƒèµ„æ–™

    [Bilibili: Flash Attention ä¸ºä»€ä¹ˆé‚£ä¹ˆå¿«ï¼ŸåŸç†è®²è§£](https://www.bilibili.com/video/BV1UT421k7rA)

    [Bilibili: ã€7ã€‘Flash Attention åŸç†è®²è§£](https://www.bilibili.com/video/BV17CPkeEEHH)

   - å®ç°éƒ¨åˆ†
